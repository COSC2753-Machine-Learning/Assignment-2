{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Exploratory Data Analysis\n",
    "---\n",
    "\n",
    "In the process of **Exploratory Data Analysis (EDA)**, our primary focus will be on conducting a comprehensive examination of these follwing attributes in the images from the provided dataset. This observation will enable us to extract insights and understand the underlying patterns that would be instrumental in forming our subsequent **Data Preprocessing** process.\n",
    "| **Attribute**   | **Description**                                                                              | **Usage**                                                                                                                                                                                    |\n",
    "|--------------|-------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| FileType     | Refers to the image file extension                                                        | Different file formats contain distinctive elements might potentially impact data consistency. These varying file types will be converted into a uniform format in the data preprocessing format, ensuring homogeneity and compatibility with analysis tools.  |\n",
    "| Width        | The image width, measured in pixels                                                     | The width of an image can influence the image's resolution and overall size. To maintain consistency when feeding data into models, images may need resizing or changing in resolution.    |\n",
    "| Height       | The image height, also measured in pixels                                                     | The height of an image can influence the image's resolution and overall size. To maintain consistency when feeding data into models, images may need resizing or changing in resolution.   |\n",
    "| Ratio        | The aspect ratio of the image, computed by dividing the Width by the Height     | The ratio attribute, another crucial aspect, comes under observation. Standardizing image dimensions during the data processing phase necessitates this. Identifying the most common ratio among images will allow the selection of an optimal cropping ratio, preserving the majority of images' integrity and content.    |\n",
    "| Mode         | The operational mode of the image                                       | Mode, an attribute connected to an image's transparency feature, receives close attention. A few selected modes support the alpha channel, critical for rendering transparency. This attribute's observation ensures image compatibility with these modes.                                                                           |\n",
    "| Bands        | A string that contains all the bands of an image, each separated by a space character                                 | The bands of an image can provide information about the color and depth of the image. Understanding the bands can help in image processing tasks such as color correction or image enhancement.  |\n",
    "| Transparency | If the image possesses transparency                                                     | The identification and processing of transparent images receive priority due to the poor performance of machine learning algorithms with such images. This step mitigates potential issues during the machine learning phase.   |\n",
    "| Animated     | If the image contains more than one frame                                               | Given that machine learning algorithms cannot directly process images containing more than one frame, any animated images in the dataset require isolation and individual frame extraction.       |\n",
    "| Class        | Furniture category that the image belongs to, within the eight provided Furniture Categories: beds, chairs, dressers, lamps, sofas, tables | This process includes checking whether category distribution is even or skewed, which could impact machine learning models' performance.                                                                    |\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(module_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Custom utils functions\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_duplicates, visualize_duplicates\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_countplot, create_k_samples\n",
      "File \u001b[0;32m~/Downloads/Assignment-2/Model/utils/dataset.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubsetRandomSampler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# Environment setups\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Utils functions\n",
    "from utils.dataset import load\n",
    "from utils.preprocess import find_duplicates, visualize_duplicates\n",
    "from utils.plotting import create_countplot, create_k_samples\n",
    "\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define Variables\n",
    "rawDataPath = \"../Data/Furniture_Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "---\n",
    "Load dataset using the imported `load()` function from `dataset` file.\n",
    "\n",
    "This function loads image data from a directory and populates a dictionary with the above-mentioned attributes of the image. \n",
    "\n",
    "\n",
    "If any image fails to load due to either being unidentified or a permission error, it gets skipped and an error message gets printed. \n",
    "\n",
    "\n",
    "The function finally returns a pandas DataFrame constructed from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "furniture_dataset = load(rawDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Duplication\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the `k` number of images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_k_samples(rawDataPath, furniture_dataset, k=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `find_duplicates` find duplicate items in the dataset by computing a perceptual hash (pHash) for each image.\n",
    "\n",
    "If the hash values of items are the same, they are consider duplication of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_df = find_duplicates(furniture_dataset, rawDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `visualize_duplicates` w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_duplicates(duplicates_df, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the duplicates dataframe\n",
    "print(len(duplicates_df), \"duplicated images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the visualization above, there are almost 20,000 duplicated images in our dataset which could contribute to the noise in the dataset, not ideal for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "furniture_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the countplot of the furniture dataset\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# Create countplots for each column in the dataset\n",
    "create_countplot(furniture_dataset, 'FileType', ax[0, 0])\n",
    "create_countplot(furniture_dataset, 'Width', ax[0, 1])\n",
    "create_countplot(furniture_dataset, 'Height', ax[0, 2])\n",
    "create_countplot(furniture_dataset, 'Ratio', ax[1, 0])\n",
    "create_countplot(furniture_dataset, 'Mode', ax[1, 1])\n",
    "create_countplot(furniture_dataset, 'Bands', ax[1, 2])\n",
    "create_countplot(furniture_dataset, 'Transparency', ax[2, 0])\n",
    "create_countplot(furniture_dataset, 'Animated', ax[2, 1])\n",
    "create_countplot(furniture_dataset, 'Category', ax[2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of interior styles\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=furniture_dataset, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Furniture Categories')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA For each Category\n",
    "\n",
    "# Beds\n",
    "\n",
    "beds_df = furniture_dataset[furniture_dataset['Category'] == 'beds']\n",
    "\n",
    "# Plot the countplot of interior styles for beds\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=beds_df, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Interior Styles for Beds')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chairs\n",
    "\n",
    "chairs_df = furniture_dataset[furniture_dataset['Category'] == 'chairs']\n",
    "\n",
    "# Plot the countplot of interior styles for chairs\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=chairs_df, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Interior Styles for Chairs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dressers\n",
    "\n",
    "dressers_df = furniture_dataset[furniture_dataset['Category'] == 'dressers']\n",
    "\n",
    "# Plot the countplot of interior styles for dressers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=dressers_df, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Interior Styles for Dressers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lamps\n",
    "\n",
    "lamps_df = furniture_dataset[furniture_dataset['Category'] == 'lamps']\n",
    "\n",
    "# Plot the countplot of interior styles for lamps\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=lamps_df, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Interior Styles for Lamps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sofas\n",
    "\n",
    "sofas_df = furniture_dataset[furniture_dataset['Category'] == 'sofas']\n",
    "\n",
    "# Plot the countplot of interior styles for sofas\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=sofas_df, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Interior Styles for Sofas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables\n",
    "\n",
    "tables_df = furniture_dataset[furniture_dataset['Category'] == 'tables']\n",
    "\n",
    "# Plot the countplot of interior styles for tables\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=tables_df, x='Interior_Style')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Count of Interior Styles for Tables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
