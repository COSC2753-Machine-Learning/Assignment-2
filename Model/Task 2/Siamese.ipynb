{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import IPython\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the shape of the inputs for our network\n",
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the batch size and number of epochs\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 8\n",
    "EPOCHS_MLP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the base output directory\n",
    "BASE_OUTPUT = \"../../Results\"\n",
    "# Use the base output path to derive the path to the serialized\n",
    "# Model along with training history plot\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined functions\n",
    "\n",
    "def contrastive_loss(y, preds, margin=1):\n",
    "\t# Explicitly cast the true class label data type to the predicted class label data type (otherwise we run the risk of having two separate data types, causing TensorFlow to error out)\n",
    "\ty = tf.cast(y, preds.dtype)\n",
    "\t\n",
    "    # Calculate the contrastive loss between the true labels and the predicted labels\n",
    "\tsquaredPreds = K.square(preds)\n",
    "\tsquaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "\tloss = K.mean((1 - y) * squaredPreds + y * squaredMargin)\n",
    "\t\n",
    "\t# Return the computed contrastive loss to the calling function\n",
    "\treturn loss\n",
    "\n",
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "\t# Specify the inputs for the feature extractor network\n",
    "\tinputs = Input(inputShape)\n",
    " \n",
    "\t# Define the first set of CONV => RELU => POOL => DROPOUT layers 64 filters 2x2\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs) # Si entrada 28x28x1 -> 28x28x64\n",
    "\tx = MaxPooling2D(pool_size=2)(x) # Si entrada 28x28x64 -> 14x14x64\n",
    "\tx = Dropout(0.3)(x)\n",
    " \n",
    "\t# Second set of CONV => RELU => POOL => DROPOUT layers 64 filters 2x2\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x) # Si entrada 14x14x64 -> 14x14x64\n",
    "\tx = MaxPooling2D(pool_size=2)(x) # Si entrada 14x14x64 -> 7x7x64\n",
    "\tx = Dropout(0.3)(x)\n",
    " \n",
    " \t# Prepare the final outputs\n",
    "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
    "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
    "\t\n",
    "\t# Build the model\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t\n",
    "\t# Return the model to the calling function\n",
    "\treturn model\n",
    "\n",
    "def get_pairs_route(images_dir, data_df, image_shape):\n",
    "\timages = []\n",
    "\tlabels = []\n",
    "\tnames = []\n",
    "\t# We use the product type as different classes\n",
    "\tnumClasses = data_df[\"Category\"].unique()\n",
    " \n",
    "\tfor i in os.listdir(images_dir):\n",
    "\t\tlabel = data_df[data_df[\"Image\"]==i].ProductType.item()\n",
    "\t\t\n",
    "\t\t# Load the image\n",
    "\t\timage = Image.open(images_dir+\"/\"+i)\n",
    "\t\n",
    "\t\t# All images should be same size\n",
    "\t\timage_resize = image.resize((image_shape[0], image_shape[0]))\n",
    "\t\t# Convert image to numpy array\n",
    "\t\tif(image_shape[2] == 1):\n",
    "\t\t\tchannel_img = image_resize.convert(\"L\")\n",
    "\t\telif(image_shape[2] == 3):\n",
    "\t\t\tchannel_img = image_resize.convert(\"RGB\")\n",
    "\n",
    "\t\tdata = np.asarray(channel_img)\n",
    "\t\n",
    "\t\timages.append(data)\n",
    "\t\tlabels.append(label)\n",
    "\t\tnames.append(i)\n",
    "\t\n",
    "\treturn np.stack(images), np.stack(labels), np.stack(names)\n",
    "\n",
    "def make_pairs(images, labels):\n",
    "\t# Initialize two empty lists to hold the (image, image) pairs and labels to indicate if a pair is positive or negative\n",
    "\tpairImages = []\n",
    "\tpairLabels = []\n",
    "\t\n",
    "\t# Calculate the total number of classes present in the dataset and then build a list of indexes for each class label that provides the indexes for all examples with a given label\n",
    "\n",
    "\tclasses = np.unique(labels)\n",
    " \n",
    "\tidx = [np.where(labels == i)[0] for i in classes]\n",
    "\t\n",
    "\t# Loop over all images\n",
    "\tfor idxA in range(len(images)):\n",
    "\t\t\n",
    "\t\t# grab the current image and label belonging to the current iteration\n",
    "\t\tcurrentImage = images[idxA]\n",
    "\t\tlabel = labels[idxA]\n",
    "\t\tlabel_idx = np.where(classes == label)[0][0]\n",
    "\t\t\n",
    "\t\t# Randomly pick an image that belongs to the *same* class label\n",
    "\t\tidxB = np.random.choice(idx[label_idx])\n",
    "\t\tposImage = images[idxB]\n",
    "\t\t\n",
    "\t\t# Prepare a positive pair and update the images and labels lists, respectively\n",
    "\t\tpairImages.append([currentImage, posImage])\n",
    "\t\tpairLabels.append([1])\n",
    "\t\t\n",
    "\t\t# Grab the indices for each of the class labels *not* equal to the current label and randomly pick an image corresponding to a label *not* equal to the current label\n",
    "\t\tnegIdx = np.where(labels != label)[0]\n",
    "\t\tnegImage = images[np.random.choice(negIdx)]\n",
    "\t\t\n",
    "\t\t# Prepare a negative pair of images and update our lists\n",
    "\t\tpairImages.append([currentImage, negImage])\n",
    "\t\tpairLabels.append([0])\n",
    "\t\t\n",
    "\t# Return a 2-tuple of our image pairs and labels\n",
    "\treturn (np.array(pairImages), np.array(pairLabels))\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "\t# Unpack the vectors into separate lists\n",
    "\t(featsA, featsB) = vectors\n",
    "\n",
    "\t# Compute the sum of squared distances between the vectors\n",
    "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    \n",
    "\t# Return the euclidean distance between the vectors\n",
    "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
    "     \n",
    "\n",
    "def plot_training(H, plotPath):\n",
    "\t# Construct a plot that plots and saves the training history\n",
    "\tplt.style.use(\"ggplot\")\n",
    "\tplt.figure()\n",
    "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\tplt.plot(H.history[\"f1_m\"], label=\"train_f1\")\n",
    "\tplt.plot(H.history[\"val_f1_m\"], label=\"val_f1\")\n",
    "\tplt.title(\"Training Loss and Accuracy\")\n",
    "\tplt.xlabel(\"Epoch #\")\n",
    "\tplt.ylabel(\"Loss/F1\")\n",
    "\tplt.legend(loc=\"lower left\")\n",
    "\tplt.savefig(plotPath)\n",
    "     \n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "     \n",
    "\n",
    "def visualize_test(pairTrain_visualize, model_visualize, size=10, seed=42):\n",
    "  np.random.seed(seed)\n",
    "  sample_index = np.random.randint(pairTrain_visualize.shape[0], size=size)\n",
    "\n",
    "  # Loop over all image pairs\n",
    "  for (i, (imageA, imageB)) in enumerate(pairTrain_visualize[sample_index]):\n",
    "    \n",
    "    # Load both the images and convert them to grayscale create a copy of both the images for visualization purpose\n",
    "    origA = imageA.copy()\n",
    "    origB = imageB.copy()\n",
    "\n",
    "    if len(imageA.shape) == 3 and imageA.shape[-1] == 1:\n",
    "      imageA = imageA[:, :, 0]\n",
    "      imageB = imageB[:, :, 0]\n",
    "    \n",
    "    elif len(imageA.shape) == 4 and imageA.shape[-1] == 1:\n",
    "      imageA = imageA[:, :, :, 0]\n",
    "      imageB = imageB[:, :, :, 0]\n",
    "    \n",
    "    imageA = np.expand_dims(imageA, axis=0)\n",
    "    imageB = np.expand_dims(imageB, axis=0)\n",
    "    \n",
    "    # Use our siamese model to make predictions on the image pair, indicating whether or not the images belong to the same class\n",
    "    preds = model_visualize.predict([imageA, imageB])\n",
    "    proba = preds[0][0]\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig = plt.figure(\"Pair #{}\".format(i + 1), figsize=(4, 2))\n",
    "    if model_visualize.loss == \"binary_crossentropy\":\n",
    "      plt.suptitle(\"Similarity: {:.2f}\".format(proba))\n",
    "    else:\n",
    "      plt.suptitle(\"Distance: {:.2f}\".format(proba))\n",
    "    \n",
    "    # Show first image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(origA)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Show the second image\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(origB)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "     \n",
    "\n",
    "def get_recommendation(model, target, data, rec_number, printable=True):\n",
    "  recommended_list = []\n",
    "\n",
    "  origA = target.copy()\n",
    "  target = np.expand_dims(target, axis=0)\n",
    "\n",
    "  if len(origA.shape) == 3 and origA.shape[-1] == 1:\n",
    "      origA = origA[:, :, 0]\n",
    "\n",
    "  if len(origA.shape) == 4 and origA.shape[-1] == 1:\n",
    "      origA = origA[:, :, :, 0]\n",
    "\n",
    "  index = 0\n",
    "  for img in data:\n",
    "    \n",
    "    # Load both the images and convert them to grayscale create a copy of both the images for visualization purpose\n",
    "    origB = img.copy()\n",
    "\n",
    "    if len(origB.shape) == 3 and origB.shape[-1] == 1:\n",
    "      origB = origB[:, :, 0]\n",
    "\n",
    "    if len(origB.shape) == 4 and origB.shape[-1] == 1:\n",
    "      origB = origB[:, :, :, 0]\n",
    "    \n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Use our siamese model to make predictions on the image pair, indicating whether or not the images belong to the same class\n",
    "    preds = model.predict([target, img], verbose = 0)\n",
    "    proba = preds[0][0]\n",
    "\n",
    "    recommended_list.append((origB, proba, index))\n",
    "    index = index + 1\n",
    "  \n",
    " \n",
    "  if model.loss == \"binary_crossentropy\":\n",
    "    \n",
    "    # Better greater similarity\n",
    "    recommended_list.sort(key=lambda a: a[1], reverse=True)\n",
    "  else: \n",
    "    \n",
    "    # Better less distance\n",
    "    recommended_list.sort(key=lambda a: a[1])\n",
    "\n",
    "  count = 0\n",
    "  recommended_list_index = []\n",
    "  for (rec_img, rec_pred, aux_index) in recommended_list:\n",
    "    if count == rec_number:\n",
    "      break\n",
    "    \n",
    "    # Get the index of the recommended item in original list\n",
    "    recommended_list_index.append(aux_index)\n",
    "\n",
    "    if printable:\n",
    "      \n",
    "      # Initialize the figure\n",
    "      fig = plt.figure(\"Recommendations\", figsize=(4, 2))\n",
    "      if model.loss == \"binary_crossentropy\":\n",
    "        plt.suptitle(\"Similarity: {:.2f}\".format(rec_pred))\n",
    "      else:\n",
    "        plt.suptitle(\"Distance: {:.2f}\".format(rec_pred))\n",
    "      \n",
    "      # Show first image\n",
    "      ax = fig.add_subplot(1, 2, 1)\n",
    "      plt.imshow(origA)\n",
    "      plt.axis(\"off\")\n",
    "      \n",
    "      # Show the second image\n",
    "      ax = fig.add_subplot(1, 2, 2)\n",
    "      plt.imshow(rec_img)\n",
    "      plt.axis(\"off\")\n",
    "      \n",
    "      # Show the plot\n",
    "      plt.show()\n",
    "    count += 1\n",
    "\n",
    "  return recommended_list_index\n",
    "     \n",
    "\n",
    "def recall_and_precission_at_k(model, images, labels, k, p_groups=0.05):\n",
    "  n_items = len(images)\n",
    "\n",
    "  np.array(images)\n",
    "  images = images / 255.0\n",
    "  images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "  items_index = random.sample(range(1, n_items), int(n_items*p_groups))\n",
    "  \n",
    "  sum_recall_list = []\n",
    "  sum_precission_list = []\n",
    "\n",
    "  for index in items_index:\n",
    "    \n",
    "    # The data retrieved is not given to de the net\n",
    "    target = images[index]\n",
    "    target_label = labels[index]\n",
    "    data = np.concatenate((images[:index], images[index+1:]), axis=0)\n",
    "    data_labels = np.concatenate((labels[:index], labels[index+1:]), axis=0)\n",
    "\n",
    "    # Get top recommendations\n",
    "    top_index = get_recommendation(model, target, data, k, printable=False)\n",
    "    top_labels = data_labels[top_index].tolist()\n",
    "\n",
    "    # Compute Rel_k/Rel\n",
    "    data_labels = data_labels.tolist()\n",
    "    rel = data_labels.count(target_label)\n",
    "\n",
    "    rel_at_k = top_labels.count(target_label)\n",
    "    sum_recall_list.append(rel_at_k / rel)\n",
    "\n",
    "    # Compute Rel_k/k\n",
    "    sum_precission_list.append(rel_at_k / k)\n",
    "\n",
    "  return sum(sum_recall_list) / len(sum_recall_list), sum(sum_precission_list) / len(sum_precission_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
