{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import os, sys\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Add the module path to the sys.path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local helper files\n",
    "from utils.dataset import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available CUDA devices: {num_gpus}\")\n",
    "    \n",
    "    # Print the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "# Set the device\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the shape of the inputs for our network\n",
    "IMG_SIZE = 120\n",
    "CROP_SIZE = 110\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the batch size, number of epochs, and the size of the chunks\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 8\n",
    "CHUNK_SIZE = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Dataset\n",
    "class FurniturePairDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.data_df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.color_histograms = []\n",
    "        self.edge_histograms = []\n",
    "        self._load_images_and_features()\n",
    "\n",
    "    def _load_images_and_features(self):\n",
    "        for idx in range(len(self.data_df)):\n",
    "            try: \n",
    "                img_name = os.path.join(self.root_dir, self.data_df.iloc[idx, 0])\n",
    "                image = Image.open(img_name)\n",
    "                self.images.append(image)\n",
    "                self.color_histograms.append(self._extract_color_histogram(image))\n",
    "                self.edge_histograms.append(self._extract_edge_histogram(image))\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_name}: {e}\")\n",
    "\n",
    "    def _extract_color_histogram(self, image):\n",
    "        image = np.array(image.convert(\"RGB\"))\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        return hist.flatten()\n",
    "\n",
    "    def _extract_edge_histogram(self, image):\n",
    "        image = np.array(image.convert(\"L\"))\n",
    "        edges = cv2.Canny(image, 100, 200)\n",
    "        hist = cv2.calcHist([edges], [0], None, [256], [0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        return hist.flatten()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df) * 2  # Each image will appear in one positive and one negative pair\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_idx = idx // 2\n",
    "        anchor_image = self.images[anchor_idx]\n",
    "        anchor_color_hist = self.color_histograms[anchor_idx]\n",
    "        anchor_edge_hist = self.edge_histograms[anchor_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            anchor_image = self.transform(anchor_image)\n",
    "\n",
    "        if idx % 2 == 0:\n",
    "            similar_idx = self._find_most_similar(anchor_idx, anchor_color_hist)\n",
    "            similar_image = self.images[similar_idx]\n",
    "\n",
    "            if self.transform:\n",
    "                similar_image = self.transform(similar_image)\n",
    "\n",
    "            return (anchor_image, similar_image), 1\n",
    "        else:\n",
    "            dissimilar_idx = self._find_most_dissimilar(anchor_idx, anchor_edge_hist)\n",
    "            dissimilar_image = self.images[dissimilar_idx]\n",
    "\n",
    "            if self.transform:\n",
    "                dissimilar_image = self.transform(dissimilar_image)\n",
    "\n",
    "            return (anchor_image, dissimilar_image), 0\n",
    "\n",
    "    def _find_most_similar(self, anchor_idx, anchor_hist):\n",
    "        max_similarity = -1\n",
    "        similar_idx = -1\n",
    "        for idx in range(len(self.data_df)):\n",
    "            if idx == anchor_idx:\n",
    "                continue\n",
    "            hist = self.color_histograms[idx]\n",
    "            similarity = cv2.compareHist(anchor_hist, hist, cv2.HISTCMP_CORREL)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                similar_idx = idx\n",
    "        return similar_idx\n",
    "\n",
    "    def _find_most_dissimilar(self, anchor_idx, anchor_hist):\n",
    "        min_similarity = 1\n",
    "        dissimilar_idx = -1\n",
    "        for idx in range(len(self.data_df)):\n",
    "            if idx == anchor_idx:\n",
    "                continue\n",
    "            hist = self.edge_histograms[idx]\n",
    "            similarity = cv2.compareHist(anchor_hist, hist, cv2.HISTCMP_CORREL)\n",
    "            if similarity < min_similarity:\n",
    "                min_similarity = similarity\n",
    "                dissimilar_idx = idx\n",
    "        return dissimilar_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "dataPath = '../../Data/Processed_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "furniture_dataset = load(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "furniture_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation logic\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),\n",
    "    torchvision.transforms.RandomCrop((110, 110)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Siamese Network using PyTorch\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_shape, embedding_dim=48):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=2, padding=1)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(-1, 64)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Euclidean distance layer\n",
    "class EuclideanDistance(nn.Module):\n",
    "    def forward(self, featsA, featsB):\n",
    "        return F.pairwise_distance(featsA, featsB, keepdim=True)\n",
    "\n",
    "# Define the complete Siamese Network model\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, input_shape, embedding_dim=48):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.feature_extractor = SiameseNetwork(input_shape, embedding_dim)\n",
    "        self.euclidean_distance = EuclideanDistance()\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, inputA, inputB):\n",
    "        featsA = self.feature_extractor(inputA)\n",
    "        featsB = self.feature_extractor(inputB)\n",
    "        distance = self.euclidean_distance(featsA, featsB)\n",
    "        output = torch.sigmoid(self.fc(distance))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = SiameseModel(IMG_SHAPE).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a chunk for training\n",
    "def process_chunk_train(chunk_df, epoch, chunk_idx, num_chunks):\n",
    "    # Create the pair dataset for the chunk\n",
    "    pair_dataset = FurniturePairDataset(df=chunk_df, root_dir=dataPath, transform=transform)\n",
    "\n",
    "    # Create the pair dataloader for the chunk\n",
    "    pair_dataloader = DataLoader(pair_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Training loop for the chunk\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(pair_dataloader)\n",
    "    print(f\"Total samples in this chunk: {len(chunk_df)}\")\n",
    "    print(f\"Total batches in this chunk: {total_batches}\")\n",
    "    for batch_idx, ((imageA, imageB), labels) in enumerate(pair_dataloader):\n",
    "        imageA, imageB, labels = imageA.cuda(), imageB.cuda(), labels.float().cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imageA, imageB)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Chunk {chunk_idx + 1}/{num_chunks}, Batch {batch_idx + 1}/{total_batches}, Loss: {running_loss / (batch_idx + 1)}\")\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Chunk {chunk_idx + 1}/{num_chunks} completed in {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset in chunks for training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    num_chunks = len(furniture_dataset) // CHUNK_SIZE + 1\n",
    "    for chunk_idx in range(num_chunks):\n",
    "        chunk_df = furniture_dataset.iloc[chunk_idx * CHUNK_SIZE:(chunk_idx + 1) * CHUNK_SIZE]\n",
    "        print(f\"Processing training chunk {chunk_idx + 1}/{num_chunks}\")\n",
    "        process_chunk_train(chunk_df, epoch, chunk_idx, num_chunks)\n",
    "    scheduler.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a chunk for testing\n",
    "def process_chunk_test(chunk_df):\n",
    "    # Create the pair dataset for the chunk\n",
    "    pair_dataset = FurniturePairDataset(df=chunk_df, root_dir=dataPath, transform=transform)\n",
    "\n",
    "    # Create the pair dataloader for the chunk\n",
    "    pair_dataloader = DataLoader(pair_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Testing loop for the chunk\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(pair_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, ((imageA, imageB), labels) in enumerate(pair_dataloader):\n",
    "            imageA, imageB, labels = imageA.cuda(), imageB.cuda(), labels.float().cuda()\n",
    "            outputs = model(imageA, imageB)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            running_loss += loss.item()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Chunk Test completed in {elapsed_time:.2f} seconds, Test Loss: {running_loss/total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset in chunks for testing\n",
    "num_chunks = len(furniture_dataset) // CHUNK_SIZE + 1\n",
    "for chunk_idx in range(num_chunks):\n",
    "    chunk_df = furniture_dataset.iloc[chunk_idx * CHUNK_SIZE:(chunk_idx + 1) * CHUNK_SIZE]\n",
    "    print(f\"Processing test chunk {chunk_idx + 1}/{num_chunks}\")\n",
    "    process_chunk_test(chunk_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
