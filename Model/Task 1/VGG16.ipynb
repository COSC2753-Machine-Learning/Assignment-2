{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From local helper files\n",
    "from utils.helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix\n",
    "from utils.helper_train import train_model\n",
    "from utils.helper_plotting import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n",
    "from utils.helper_dataset import get_dataloaders_cifar10, UnNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 6\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([256, 3, 110, 110])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Class labels of 10 examples: tensor([1, 1, 3, 5, 3, 2, 3, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### FURNITURE_DATA\n",
    "##########################\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),\n",
    "    torchvision.transforms.RandomCrop((110, 110)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),        \n",
    "    torchvision.transforms.CenterCrop((110, 110)),            \n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "path = \"../../Furniture_data/\"\n",
    "train_val_test_split = [0.7, 0.2, 0.1]\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(root=path, transform=train_transforms)\n",
    "\n",
    "# Determine sizes for each split\n",
    "total_size = len(dataset)\n",
    "train_size = int(train_val_test_split[0] * total_size)\n",
    "valid_size = int(train_val_test_split[1] * total_size)\n",
    "test_size = total_size - train_size - valid_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Apply test transform to validation and test datasets\n",
    "valid_dataset.dataset.transform = test_transforms\n",
    "test_dataset.dataset.transform = test_transforms\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block_1 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=3,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=64,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_2 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=64,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=128,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = torch.nn.Sequential(        \n",
    "                torch.nn.Conv2d(in_channels=128,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "          \n",
    "        self.block_4 = torch.nn.Sequential(   \n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_5 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                                out_channels=512,\n",
    "                                kernel_size=(3, 3),\n",
    "                                stride=(1, 1),\n",
    "                                padding=1),\n",
    "                torch.nn.ReLU(),    \n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                   stride=(2, 2))             \n",
    "        )\n",
    "            \n",
    "        height, width = 3, 3 ## Varies based on image size\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512*height*width, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, num_classes),\n",
    "        )\n",
    "            \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.torch.nn.Conv2d) or isinstance(m, torch.torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "                    \n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((height, width))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        return logits                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(num_classes=6)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_on='valid_acc',\n",
    "    logging_interval=100)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=200)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "plt.ylim([60, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
